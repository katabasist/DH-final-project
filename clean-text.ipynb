{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42e4c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: tp0208.txt\n",
      "Processed: tp0221.txt\n",
      "Processed: tp0219.txt\n",
      "Processed: tp0213.txt\n",
      "Processed: tp0216.txt\n",
      "Processed: tp0202.txt\n",
      "Processed: tp0206.txt\n",
      "Processed: tp0222.txt\n",
      "Processed: tp0214.txt\n",
      "Processed: tp0201.txt\n",
      "Processed: tp0215.txt\n",
      "Processed: tp0205.txt\n",
      "Processed: tp0210.txt\n",
      "Processed: tp0203.txt\n",
      "Processed: tp0212.txt\n",
      "Processed: tp0220.txt\n",
      "Processed: tp0218.txt\n",
      "Processed: tp0217.txt\n",
      "Processed: tp0207.txt\n",
      "Processed: tp0204.txt\n",
      "Processed: tp0209.txt\n",
      "Processed: tp0211.txt\n",
      "\n",
      "Character frequencies:\n",
      "FADE OUT: 7298\n",
      "REVISED: 3624\n",
      "FADE TO BLACK: 2020\n",
      "SUDDENLY: 1186\n",
      "INTERCUT: 1017\n",
      "REVISIONS: 621\n",
      "BOARD MEMBERS: 581\n",
      "INTERCUT WITH: 577\n",
      "POV: 486\n",
      "ITEM: 366\n",
      "SECOND DRAFT: 316\n",
      "FIRST DRAFT: 249\n",
      "MATCH WITH: 184\n",
      "MATCH CUT TO: 183\n",
      "SHOCK CUT TO: 169\n",
      "QUICK DISSOLVE: 74\n",
      "FADE TO WHITE: 36\n",
      "FLASHBACK: 13\n",
      "CUT TO BLACK: 10\n",
      "ANGLE: 8\n",
      "FIRST DRAFT DATE: 5\n",
      "SMASH CUT TO: 3\n",
      "GENERAL DISTRIBUTION: 1\n",
      "DRAFT DATE: 1\n",
      "REVISED DRAFT: 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def normalize_character_name(name):\n",
    "    \"\"\"Merge character name variants (e.g., 'WAITER (CONTINUED)' -> 'WAITER')\"\"\"\n",
    "    # Remove parentheticals and suffixes\n",
    "    name = re.sub(r'\\(.*?\\)', '', name).strip()\n",
    "    # Remove \"CONT'D\" or \"CONTINUED\" markers\n",
    "    name = re.sub(r'\\b(CONT\\'D|CONTINUED)\\b', '', name, flags=re.IGNORECASE).strip()\n",
    "    # Remove voiceover markers (V.O.)\n",
    "    name = re.sub(r'\\bV\\.O\\.\\b', '', name).strip()\n",
    "    # Standardize to ALL CAPS (for consistency)\n",
    "    return name.upper()\n",
    "\n",
    "def clean_twin_peaks_script(raw_text):\n",
    "    \"\"\"Advanced cleaning with character normalization\"\"\"\n",
    "    # Remove revision headers and page numbers\n",
    "    text = re.sub(r'^\\d+\\.\\n', '', raw_text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\.{3}.*?YELLOW.*?\\n', '', text)\n",
    "    \n",
    "    # Remove scene headings and technical directions\n",
    "    text = re.sub(r'^(INT\\.|EXT\\.|FADE IN:|CUT TO:|DISSOLVE TO:|ESTABLISH\\.).*$', '', \n",
    "                 text, flags=re.MULTILINE|re.IGNORECASE)\n",
    "    \n",
    "    # Remove parentheticals and actor directions\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove ALL-CAPS action lines (but preserve character names)\n",
    "    text = re.sub(r'^[A-Z][A-Z\\s]+\\n', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Process line by line to normalize characters\n",
    "    cleaned_lines = []\n",
    "    current_character = None\n",
    "    \n",
    "    for line in text.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        # Character line detection (supports \"CHARACTER:\" and \"CHARACTER (CONTINUED):\")\n",
    "        char_match = re.match(r'^([A-Z][A-Z\\s]+?(?:\\(.*?\\))?):\\s*(.*)$', line)\n",
    "        if char_match:\n",
    "            raw_name, dialogue = char_match.groups()\n",
    "            normalized_name = normalize_character_name(raw_name)\n",
    "            \n",
    "            # Only update character if name isn't empty after normalization\n",
    "            if normalized_name:\n",
    "                current_character = normalized_name\n",
    "                cleaned_lines.append(f\"{current_character}: {dialogue}\")\n",
    "        elif current_character and line:\n",
    "            # Continuation of previous character's dialogue\n",
    "            cleaned_lines.append(f\"{current_character}: {line}\")\n",
    "    \n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "# Batch processing\n",
    "input_folder = \"episode-text\"\n",
    "output_folder = \"cleaned-text\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "character_counts = defaultdict(int)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(input_folder, filename), 'r', encoding='utf-8', errors='replace') as f:\n",
    "            raw_text = f.read()\n",
    "        \n",
    "        cleaned_text = clean_twin_peaks_script(raw_text)\n",
    "        \n",
    "        # Count characters for analysis\n",
    "        for line in cleaned_text.split('\\n'):\n",
    "            if ':' in line:\n",
    "                char = line.split(':')[0].strip()\n",
    "                character_counts[char] += 1\n",
    "        \n",
    "        # Save cleaned file\n",
    "        output_path = os.path.join(output_folder, f\"norm_{filename}\")\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(cleaned_text)\n",
    "        \n",
    "        print(f\"Processed: {filename}\")\n",
    "\n",
    "# Print character frequency (optional)\n",
    "print(\"\\nCharacter frequencies:\")\n",
    "for char, count in sorted(character_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{char}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
